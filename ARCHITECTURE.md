# System Architecture

This document provides a technical overview of the License Plate Detector system architecture, components, and data flow.

## ğŸ—ï¸ Architecture Overview

The system follows a modular architecture with three main components:

```mermaid
graph TB
    A[Dataset Preparation] --> B[Model Training]
    B --> C[Model Inference]
    D[Data Preprocessing Utilities] --> A
    E[Pre-trained YOLO11] --> B
    B --> F[Trained Weights]
    F --> C
    C --> G[Detection Results]
```

## ğŸ“¦ Core Components

### 1. Data Preprocessing Module

**Purpose**: Convert, validate, and prepare datasets for YOLO training

**Key Scripts**:
- `convert_xml_to_txt.py` - XML to YOLO format converter
- `check_dataset.py` - Dataset integrity validator
- `create_empty_labels.py` - Empty label file generator
- `rename_img_labels.py` - Batch file renamer

**Data Flow**:
```
Raw Annotations (XML) â†’ convert_xml_to_txt.py â†’ YOLO Format (.txt)
                                                        â†“
                                                check_dataset.py
                                                        â†“
                                                 Validated Dataset
```

### 2. Training Module

**Purpose**: Train and fine-tune YOLO11 models on custom license plate datasets

**Location**: `training/`

**Key Components**:
- **train.py**: Initial training script
  - Loads pre-trained YOLO11n (nano) model
  - Configures training hyperparameters
  - Saves checkpoints and best weights
  
- **resume_train.py**: Resume interrupted training
  - Loads last checkpoint
  - Continues from previous epoch

**Training Pipeline**:
```
Pre-trained YOLO11n â†’ Load Dataset â†’ Training Loop â†’ Validation â†’ Save Weights
        â†“                                    â†“
   yolo11n.pt                         runs/*/weights/
                                      â”œâ”€â”€ best.pt
                                      â””â”€â”€ last.pt
```

**Training Configuration**:
```python
{
    "model": "yolo11n.pt",      # Nano variant (fastest)
    "epochs": 100,
    "image_size": 640,
    "batch_size": 16,
    "device": 0,                # GPU
    "optimizer": "auto",        # Automatic optimizer selection
    "augmentation": "auto"      # Automatic augmentation
}
```

### 3. Inference Module

**Purpose**: Detect license plates in various input sources

**Location**: `inference/`

**Scripts**:

| Script | Input | Output | Use Case |
|--------|-------|--------|----------|
| `detect_image.py` | Single image | Displayed result | Testing, single image processing |
| `detect_video.py` | Video file | Saved video with detections | Batch video processing |
| `detect_webcam.py` | Webcam stream | Real-time display | Live monitoring, simple demos |
| **`run_model.py`** | Webcam stream | Real-time display + UI | **Production webcam detection with controls** |

**Inference Pipeline**:
```
Input Source â†’ Load Model â†’ Preprocessing â†’ Detection â†’ Post-processing â†’ Output
                   â†“
              best.pt
```

**Detection Process**:
1. **Input Loading**: Read image/video/webcam frame
2. **Preprocessing**: Resize to 640Ã—640, normalize
3. **Model Forward Pass**: YOLO11 backbone + detection head
4. **Post-processing**: Non-max suppression (NMS), confidence filtering
5. **Output**: Bounding boxes with class labels and confidence scores

## ğŸ§  Model Architecture

### YOLO11 Nano (yolo11n.pt)

**Architecture Characteristics**:
- **Type**: Single-shot object detector
- **Backbone**: CSPDarknet (lightweight variant)
- **Neck**: PANet (Path Aggregation Network)
- **Head**: YOLO detection head
- **Input Size**: 640Ã—640 pixels
- **Output**: Bounding boxes [x, y, w, h] + class probabilities

**Model Variants**:
- **yolo11n** (nano): Fastest, lowest accuracy (~2.6M parameters)
- **yolo11s** (small): Balanced speed/accuracy
- **yolo11m** (medium): Higher accuracy
- **yolo11l** (large): High accuracy, slower
- **yolo11x** (extra-large): Best accuracy, slowest

Current implementation uses **yolo11n** for speed optimization.

### Custom Training Adaptations

The model is fine-tuned for:
- Single class detection: "Kataho_Plate"
- Input images: License plate images (various sizes)
- Transfer learning: Pre-trained on COCO â†’ Fine-tuned on custom dataset

## ğŸ“Š Data Format

### YOLO Label Format

Each image has a corresponding `.txt` file with annotations:

```
<class_id> <x_center> <y_center> <width> <height>
```

**Example**:
```
0 0.512 0.347 0.284 0.156
```

- All values normalized to [0, 1]
- `x_center`, `y_center`: Center of bounding box
- `width`, `height`: Box dimensions
- `class_id`: 0 for "Kataho_Plate"

### Dataset Configuration (data.yaml)

```yaml
path: /absolute/path/to/dataset       # Dataset root
train: /path/to/dataset/images/train  # Training images
val: /path/to/dataset/images/val      # Validation images
test: /path/to/dataset/images/val     # Test images (same as val)

nc: 1                                 # Number of classes
names:
  - Kataho_Plate                      # Class name
```

## ğŸ”„ Data Flow Diagram

### Complete System Flow

```mermaid
flowchart LR
    A[Raw Images + XML] --> B[convert_xml_to_txt.py]
    B --> C[YOLO Format Dataset]
    C --> D[check_dataset.py]
    D --> E{Valid?}
    E -->|No| F[Fix Issues]
    F --> D
    E -->|Yes| G[train.py]
    G --> H[Trained Model]
    H --> I[Inference Scripts]
    I --> J[detect_image.py]
    I --> K[detect_video.py]
    I --> L[detect_webcam.py]
    J --> M[Results]
    K --> M
    L --> M
```

### Training Data Flow

```mermaid
sequenceDiagram
    participant D as Dataset
    participant L as DataLoader
    participant M as YOLO11 Model
    participant O as Optimizer
    participant V as Validator
    
    D->>L: Load batch
    L->>M: Forward pass
    M->>M: Calculate loss
    M->>O: Backpropagation
    O->>M: Update weights
    M->>V: Validation
    V->>M: Metrics (mAP, precision, recall)
```

## ğŸ—‚ï¸ Directory Structure Explained

```
Plate-Detector/
â”œâ”€â”€ dataset/                    # Training data
â”‚   â”œâ”€â”€ data.yaml              # Dataset config (paths, classes)
â”‚   â”œâ”€â”€ images/
â”‚   â”‚   â”œâ”€â”€ train/            # Training images (~70-80%)
â”‚   â”‚   â””â”€â”€ val/              # Validation images (~20-30%)
â”‚   â””â”€â”€ labels/
â”‚       â”œâ”€â”€ train/            # YOLO format labels
â”‚       â””â”€â”€ val/              # Validation labels
â”‚
â”œâ”€â”€ training/                   # Training scripts
â”‚   â”œâ”€â”€ train.py              # Initial training
â”‚   â”œâ”€â”€ resume_train.py       # Resume from checkpoint
â”‚   â””â”€â”€ runs/                 # Training outputs
â”‚       â””â”€â”€ plate_detector_yolo11/
â”‚           â”œâ”€â”€ weights/      # Model checkpoints
â”‚           â”‚   â”œâ”€â”€ best.pt   # Best validation mAP
â”‚           â”‚   â””â”€â”€ last.pt   # Last epoch
â”‚           â”œâ”€â”€ results.png   # Training curves
â”‚           â””â”€â”€ confusion_matrix.png
â”‚
â”œâ”€â”€ inference/                  # Inference scripts
â”‚   â”œâ”€â”€ detect_image.py       # Single image detection
â”‚   â”œâ”€â”€ detect_video.py       # Video processing
â”‚   â””â”€â”€ detect_webcam.py      # Basic real-time detection
â”‚
â”œâ”€â”€ Helper_Files/               # Data preprocessing utilities
â”‚   â”œâ”€â”€ check_dataset.py      # Validate labels
â”‚   â”œâ”€â”€ convert_xml_to_txt.py # XML â†’ YOLO conversion
â”‚   â”œâ”€â”€ create_empty_labels.py # Generate empty labels
â”‚   â””â”€â”€ rename_img_labels.py  # Rename files
â”‚
â””â”€â”€ run_model.py                # Advanced webcam detection with UI
```

## ğŸ”§ Key Dependencies

| Dependency | Purpose | Version |
|------------|---------|---------|
| `ultralytics` | YOLOv11 framework | Latest |
| `torch` | Deep learning backend | â‰¥1.8.0 |
| `torchvision` | Image transformations | Compatible |
| `opencv-python` | Image/video processing | Latest |
| `numpy` | Numerical operations | Latest |

### Dependency Roles

- **ultralytics**: Provides YOLO11 model architecture, training loop, and inference
- **PyTorch**: Neural network backend, GPU acceleration
- **OpenCV**: Image I/O, video processing, webcam access
- **NumPy**: Array operations, coordinate transformations

## âš¡ Performance Considerations

### Training Performance

- **GPU Utilization**: ~70-90% on single GPU
- **Training Speed**: ~100 images/sec (depends on GPU)
- **Memory Usage**: ~4-6 GB VRAM (batch=16, yolo11n)

### Inference Performance

| Input Type | FPS | Latency | Device |
|------------|-----|---------|--------|
| Image | N/A | ~20ms | GPU |
| Video | ~45-60 | ~16-22ms | GPU |
| Webcam | ~30-45 | ~22-33ms | GPU |

*Performance measured on NVIDIA RTX series GPU*

## ğŸ” Model Persistence

**Training Outputs**:
```
runs/plate_detector_yolo11/
â”œâ”€â”€ weights/
â”‚   â”œâ”€â”€ best.pt              # Best model (lowest validation loss)
â”‚   â””â”€â”€ last.pt              # Last training epoch
â”œâ”€â”€ results.csv              # Epoch-wise metrics
â”œâ”€â”€ results.png              # Training/validation curves
â”œâ”€â”€ confusion_matrix.png     # Classification matrix
â””â”€â”€ args.yaml                # Training arguments
```

**Recommended for Inference**: Use `best.pt` for optimal detection accuracy.

## ğŸš€ Optimization Opportunities

### Current Architecture
- Model: YOLO11n (nano) - optimized for speed
- Batch size: 16 - balanced memory/speed
- Input size: 640Ã—640 - standard YOLO resolution

### Potential Improvements
1. **Accuracy**: Upgrade to `yolo11s` or `yolo11m` for better detection
2. **Speed**: Reduce input size to 416Ã—416 for faster inference
3. **Scalability**: Implement batch inference for video processing
4. **Deployment**: Export to ONNX/TensorRT for production

---

For implementation details, see [USAGE_GUIDE.md](USAGE_GUIDE.md) and [API_REFERENCE.md](API_REFERENCE.md).
